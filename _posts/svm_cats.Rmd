---
title: "Support Vector Machine"
author: "Loy"
date: "Thursday, March 19, 2015"
output: pdf_document
---

An example on Support Vector Machine.  
For this we require package "e1071" and "MASS" for cats dataset.  
In this example we will try to predict the sex of cat using body weight and heart weight variables.
```{r warning=FALSE,message=FALSE}
require(e1071)
require(MASS)
data(cats)
head(cats)
dim(cats)
input.data <- data.frame(cats[, c(2,3)], response = as.factor(cats$Sex))
```  

We build the linear SVM model.
```{r}
svm.fit <- svm(response ~., data = input.data, kernel = "linear", cost = 10, scale = FALSE)
summary(svm.fit)
plot(svm.fit, input.data)
table(input.data$response, predict(svm.fit))
mean(input.data$response != predict(svm.fit))
```  

We will also build radial SVM model. When a radial kernel is used the resulting hyperplane need not to be a line anymore. A curved region of separation is usually defined to demarcate the separation between classes, often leading to higher accuracy with the data.
```{r}
svmfit <- svm(response ~., data = input.data, kernel = "radial", cost = 10, scale = FALSE)
summary(svmfit)
plot(svmfit, input.data)
table(input.data$response, predict(svmfit))
mean(input.data$response != predict(svmfit))
```  

We can find optimal parameters using tune.svm() function. First we'll separate the data into train and test dataset.
```{r}
set.seed(300)
train <- sample(1:nrow(input.data), .8*nrow(input.data))
cats.train <- input.data[train, ]
cats.test <- input.data[-train, ]
dim(cats.train)
dim(cats.test)
tuned <- tune.svm(response ~., data = cats.train, cost = 10^(1:2),
                  gamma = 10^(-6:-1))
summary(tuned)

```  

We will use the parameters that we got from tuned model.
```{r}
new.svmfit <- svm(response ~., data = cats.train, kernel = "radial",
                  cost = 10, gamma = 0.1, scale = FALSE)
summary(new.svmfit)
plot(new.svmfit, cats.train)
table(cats.test$response, predict(new.svmfit, cats.test))
mean(cats.test$response != predict(new.svmfit, cats.test))

```

We will also make grid plot. A 2-coloured grid plot, makes is visually clear which regions of the plot is designated to which class of response by the SVM classifier.
```{r}
n_points_in_grid = 60
x_axis_range <- range(input.data[, 2])
y_axis_range <- range(input.data[, 1])
x_grid_points <- seq(from = x_axis_range[1], to = x_axis_range[2],
                     length = n_points_in_grid)
y_grid_points <- seq(from = y_axis_range[1], to = y_axis_range[2],
                     length = n_points_in_grid)
all_grid_points <- expand.grid(x_grid_points, y_grid_points)
names(all_grid_points) <- c("Hwt", "Bwt")
all_points_predicted <- predict(new.svmfit, all_grid_points)
colour_array <- c("red", "blue")[as.numeric(all_points_predicted)]
plot(all_grid_points, col = colour_array, pch = 20, cex = 0.50)
points(x = cats.train$Hwt, y = cats.train$Bwt, col = c("red", "blue")[as.numeric(cats.train$Sex)], pch = 20)
points(cats.train[new.svmfit$index, c(2, 1)], pch = 5, cex = 1)

```







